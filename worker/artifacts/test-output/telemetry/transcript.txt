 It's one of the topics that I'm interested in, because the service track is a piece on  how workloads are changing, how we're going to integrate different pieces of data from  CPUs and show that there's power monitoring systems back into the tenants' visibility  for fine-tuning workloads and scheduling workloads, and so primarily I wanted to talk  today about the like-maker effort that we've been working through with a number of entities  from the industry.  So, as many of you know, temperature sensors is a collection of data points where those  points come from various entities within the infrastructure, for example, there's the  commerce, temperature sensors, pressure sensors, all these different pieces of information  that we're going to be talking about.  So, the data centers are kind of a critical part of what exactly the data center is doing.  It's kind of the, you know, comparable to like any TG machine, essentially, a lot of  the entire system is within the data halls in the data center, right?  The mid-time monitoring system is essential to the operations team, so if you look at  the way data centers are operating, of course, that is absolutely critical.  How do we move into this AI function?  And, importantly, it's that type of information that's going to become important.  How can we generate back-to-the-tenants?  It's going to be work in how the super computers essentially operate within the data halls  is becoming more and more important.  The fluctuation is obviously going to be growing because the intensities of this  .  So, when you think of the building of this system, you can kind of think of a couple  different ways to compartmentalize it.  The big systems within the plant, so the provide chillers, pumps, your CDUs, your secondary  fluid temperatures.  the pressures, the pump speeds, all of those are tied into a kind of a  it's basically infrastructure. So we look at third party based on  the landlord, the building owner is responsible for the concept of  all of it. That information needs  to be readily accessible by the tenants in some shape or fashion.  Getting that documented or getting a standard set in place  for integration across the different data center users is going to be very  important. Inside the data hall, of course, there's  tenant type systems where you're looking at measuring pull down times for  SLAs, you're essentially have n feet units, you have plus weight,  you have power meters, you have voltage sets, these types of things.  Inside the data halls it's a bit easier because you can take those points  tied right back into the facility record. That makes it quite a bit easier  to work through those points.  The challenge that we're going to be facing  now is how do we get the data center back into  the tenants' visibility and ultimately also get some of the information  from the tenants back into the landlord without  particularly being a leader in building management systems.  That has yet to be solved at scale with all the different  entities. So as I mentioned previously,  with the growing demand, the growing density of these racks,  the fluctuations that may have been  happening, you know, cycling on a certain period are now going to be  much greater. So the amplitudes of those peaks and valleys will change  relative to kind of traditional AI or traditional computer storage  workloads and networking. So how does this play into the data center  infrastructure? Being able to control the infrastructure needs to be  improved. If the AI workloads can swing, you know, 20 to 30 percent, if  you look at the size of chillers and pumps and these types of things,  they're not really changing relative to the AI infrastructure.  How do you bring up a chiller preemptively knowing that you have a large training  model coming through? These types of things require some sort of communication  between the building systems and the workloads themselves. Other things need  to compensate as well for being workload profiles. So most people probably see  the GPU kind of inrushing kind of the power profiles of how it's consuming  power. That's quite a bit different than you would expect from a normal  computer storage or networking deployment. So the main piece of this  furniture white paper that we've been working on is essentially getting  information from this service provider secure network back into the tenant's  use through one lead or another, which is kind of yet to be determined. The  building management system, of course, is controlling what's happening in the  building, all these critical components. So network security is extremely important.  You can imagine what would go wrong if the building management system were to be  made public on a website or whatnot. People would be able to potentially change  lines, things like that, which would be catastrophic to the infrastructure.  On the same token, you don't want to open up a vulnerability to the tenant's private  production networks, right, because those are absolutely paramount to keeping the  privacy and all these things. So how do we bridge that gap?  How do we bridge that gap to get information transported in a timely fashion with the  right reporting frequencies? And these types of requirements is going to be something  that has to be solved. Currently, today, there's a couple different security information  options, although while clearly common, some of the reporting, so if you would imagine  as a person, so like QTT is a message you hear about querying, you're queuing to the  momentary transport, which essentially you can think of as similar to like magazines  and subscription stores. The publisher is the author of the article, or whoever owns  the data initially. The subscriber is someone who basically wants to get that data, and  the broker is essentially like the publishing house, and they're helping you get that content.  And of course the topic is specific to whatever it is that the publisher has for data or  information. So that's one technique to be able to do that. It's kind of a lightweight  protocol for sharing information amongst machines. Another good example is basically  the REST API, which is fairly common for essentially getting data and sending requests  and messages through an HTTP update. So another good example, although the reporting  update and where does the data get stored is still really important. So after you have  started to analyze, with the waveforms, say, for example, if you're looking at the data  for a bus level, being able to report the waveform for different transit modes or different  modes changing on the AI supercomputer are very important to be able to analyze. And  if you're taking snapshots of that data every one second versus 60 samples a second,  or 120 samples a second, the data storage requirements are drastically different. So  a lot of this is what we're trying to take into this telemetry sub-track through the  REST facility track. And a lot of it, like I mentioned, we've been collaborating with  OCP, of course, Microsoft, Meta, and Google. And our whole intention is to get to a point  where we can publish guidelines for third-party providers, so that way there's a framework  upon what are the right number of building management servers or storage devices that  we need to work with to get the proper data storage. Some of the other pieces are in the  common naming conversions. If you've looked at building management control systems or  any sort of like points lists, you'll know that in a building you can have tens of thousands,  if not hundreds of thousands of different points. And at the naming, most of the time,  the naming scheme is kind of, it's a dealer's choice. So it's whatever makes sense, they're  not really that . When you do third-party data centers, you don't want to end up having  to try to tailor point names across different tenants. So these are some of the things that  are going to be more prevalent in the future. And so with OCP's work, we've been working  on getting together the first four white papers to explain kind of the business need,  and then eventually set up these working rooms amongst hyperscalers, major types of  market, third-party providers, to be able to work on standardizing these things. And  probably one of the most important aspects of the separate is the security aspect of it.  We, many times, will find that tenants will not allow networking hardware or networking  pathways to leave the secure department. That makes it extremely hard to get building management  or power management points back to the tenant if you don't allow some sort of physical  transport. So these are some of the tasks that we have to solve. So one of the things  that we want to also call out very clearly, you know, we need folks to be involved in  this, whether you're a controls expert or have ideas on how we can get these transport  methodologies outlined in detail. We're always looking for support. You can either reach  out to myself or Rob Hoyle. We've got a number of folks from others that are also  participating. We set up a monthly call, although I think as we start to subdivide some of these  tasks, we'll probably set up small working groups, especially if we get into some of  the nuances of, say, point naming. Like, we probably don't need everyone to be involved  in this. We're going to try to manage that. However, coming up to a standard is going  to be just as straightforward. Then, as always, link the facility, DSM facility web  page. If you get some questions, the person who's reading this as well. But that is essentially  white paper. It is fingerprinted, and then that will be out. And then, again, the intention,  we will start to finalize that specification and implementation guide and other things  to support it to kind of go along with it.  .  .  .  I understand that the specifications .  There's no questions?  Thanks for your time.  Do you have any questions?